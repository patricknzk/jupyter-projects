{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCI1022 Python Assignment 2: Matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you have to develop code able to multiply a matrix by a vector. Matrix-vector multiplication is an absolutely fundamental operation, with countless applications in computer science and scientific computing. For example, matrix-vector multiplication lays at the core of [iterative methods](https://en.wikipedia.org/wiki/Iterative_method) for the solution of linear systems. Linear systems are ubiquitous in the numerical discretization of [Partial Differential Equations](https://en.wikipedia.org/wiki/Partial_differential_equation), as those governing the mechanics of [solids](https://en.wikipedia.org/wiki/Solid_mechanics) and [fluids](https://en.wikipedia.org/wiki/Fluid_mechanics). In all these applications, efficient algorithms for matrix-vector multiplication are of paramount importance.\n",
    "\n",
    "For simplicity, we will work with square matrices, i.e., matrices which have the same number of rows and columns. Let $A \\in  {\\rm I\\!R}^n \\times {\\rm I\\!R}^n$ be a square matrix with $n$ rows and columns, and $x \\in {\\rm I\\!R}^n$ a vector with $n$ entries. We will use the following index convention to refer to the $n \\times n$ entries of $A$ and $n$ entries of $x$:\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "a_{0,0} & a_{0,1} & \\cdots & a_{0,n-1} \\\\\n",
    "a_{1,0} & a_{1,1} & \\cdots & a_{1,n-1} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "a_{n-1,0} & a_{n-1,1} & \\cdots & a_{n-1,n-1} \n",
    "\\end{pmatrix}\n",
    "\\quad \\mathrm{and} \\quad   x =\n",
    "\\begin{pmatrix}\n",
    "           x_{0} \\\\\n",
    "           x_{1} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{n-1}\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "## Dot-product variant (a.k.a. row-variant) of matrix-vector multiplication\n",
    "\n",
    "The multiplication of $A$ by $x$ is a vector $y \\in {\\rm I\\!R}^n$ (i.e., with $n$ entries), where each entry $y_i$, with $i=0,\\ldots,n-1$, is defined as $y_i=\\sum_{j=0}^{n-1} a_{i,j} x_{j}$. In other words, the $i$-th entry of $y$ is defined as the [dot (a.k.a. Euclidean or inner)](https://en.wikipedia.org/wiki/Dot_product) product of the $i$-th row of $A$ and $x$. In the following expression, you may see how all the entries of $y$ are defined: \n",
    "\n",
    "$$\n",
    "y = \\begin{pmatrix}\n",
    "           y_{0} \\\\\n",
    "           y_{1} \\\\\n",
    "           \\vdots \\\\\n",
    "           y_{n-1}\n",
    "\\end{pmatrix} \n",
    "=\n",
    "\\begin{pmatrix}\n",
    "           \\sum_{j=0}^{n-1} a_{0,j} x_{j} \\\\\n",
    "           \\sum_{j=0}^{n-1} a_{1,j} x_{j} \\\\\n",
    "           \\vdots \\\\\n",
    "           \\sum_{j=0}^{n-1} a_{n-1,j} x_{j}\n",
    "\\end{pmatrix} \n",
    ".\n",
    "$$\n",
    "\n",
    "We will refer to this way of looking at the operation as the **dot product variant of matrix-vector product**, as indeed the dot-product is the basic operation required to obtain each entry of $y$. The dot product variant is also referred as the *row-variant* of matrix-vector multiplication, as when one implements it in a computer, the matrix $A$ is accessed by rows (i.e., we first access the first row left-to-right, then we jump to the second row and access it left-to-right, and so on, till we access the last row).  \n",
    "\n",
    "## AXPY-product variant (a.k.a. column variant) of matrix-vector multiplication\n",
    "\n",
    "However, we can look at a different way to matrix-vector multiplication. In particular, if we partition $A$ by columns\n",
    "\n",
    "$$\n",
    "A = \\left( \\begin{array}{c|c|c|c}\n",
    "           a^{0}  & \n",
    "           a^{1}  &\n",
    "           \\cdots & \n",
    "           a^{n-1}\n",
    "           \\end{array}\n",
    "     \\right)\n",
    "$$ \n",
    "\n",
    "where $a^i$ denotes the $i$-th column of $A$, then the matrix-vector product is defined as:\n",
    "\n",
    "$$\n",
    "y = \\sum_{j=0}^{n-1} a^{j} x_{j}.\n",
    "$$\n",
    "\n",
    "Note that in the expression above, $a^j$ is a vector, and $x_j$ is a scalar.  If we denote by $y^j$ the product $a^{j} x_{j}$, then each entry of $y^j$ is defined as the corresponding entry of $a^j$ multiplied by $x_j$.\n",
    "This way of looking at matrix-vector multiplication is referred to as the AXPY variant, because the basic operation to be performed is an AXPY product. An AXPY product is an operation of the form $y=\\alpha *x + y$, where $x,y$ are vectors of the same shape, and $\\alpha$ is an scalar. Note that the A in AXPY corresponds to $\\alpha$, the X to $x$, P to plus ($+$) and Y to $y$. The AXPY product variant is also referred as the *column-variant* of matrix-vector multiplication, as when one implements it in a computer, the matrix $A$ is accessed by columns (i.e., we first access the first column top-to-bottom, then we jump to the second column and access it top-to-bottom, and so on, till we access the last column).   \n",
    "\n",
    "## Struggling?\n",
    "\n",
    "If you find yourself struggling with what you have read so far, we strongly encourage to watch [this excellent video](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/matrix-vector-products) by Sal Khan (Khan academy) on matrix-vector multiplication. If not, you can continue reading.\n",
    "\n",
    "\n",
    "## Is my code correct? Measuring relative error among two vectors.\n",
    "\n",
    "In order to check that the code you have written is correct, we will compare the result computed by your code with the one computed by a built-in implementation of the matrix-vector product provided by NumPy (that we assume to be correct). If we denote by $y$ the vector computed by the latter, and by $\\tilde{y}$ the one computed by your code, we define the relative error $e$ among $y$ and $\\tilde{y}$ as:\n",
    "\n",
    "$$\n",
    "   e = \\frac{||y-\\tilde{y}||_2}{||y||_2},\n",
    "$$\n",
    "where $||\\cdot||_2$ denotes the [Euclidean norm (a.k.a. as 2-norm)](https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm). The computer can only represent a finite number of digits of a real number (memory is limited!). Indeed, recall from the previous assignment, that *a Python `float` can represent at most about 16 correct decimal digits of a real number.* Thus, floating point representation and arithmetics are subject to small round-off errors: even if your code is correct, $e$ will most probably not be exactly zero.  It can be proven mathematically that, for matrix-vector product, $e$ is on the order of the so-called [machine epsilon](https://en.wikipedia.org/wiki/Machine_epsilon), which for Python `float`s can be checked programmatically using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be more conservative and **assume that your code is correct as far as $e < 10^{-12}$**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming considerations\n",
    "\n",
    "As you might have guessed, we will use NumPy arrays to represent the matrix $A$ (2D array) and the vectors $x,y$ (1D arrays). Besides, we will stick ourselves to the following interface for the different matrix-vector product function implementations that we are going to develop along the assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_vector_multiplication(A,x):\n",
    "  \"\"\"Computes the product of A and x, and returns the result in a new 1D array\n",
    "   created within the function. A is assumed to be an square 2D array, and x\n",
    "   a 1D array. The number of entries of x is assumed to be equivalent to the\n",
    "   number of rows/columns of A.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring floating point performance using FLOPS\n",
    "\n",
    "One of the objectives of the assignment is to evaluate and compare the performance of different implementations of matrix-vector multiplication. We will use a metric known as [FLOPS](https://en.wikichip.org/wiki/flops) for such a purpose. FLOPS is defined as the number of floating point operations per unit time (per second). The larger the FLOPS the faster a computation is. Indeed, the top supercomputers in the world are ranked in the [Top500 list](https://www.top500.org/lists/top500/2020/06/) accordingly to the FLOPS that they are able to deliver when performing Gaussian elimination of a huge linear system using the so-called [LINPACK](https://en.wikipedia.org/wiki/LINPACK_benchmarks) test. \n",
    "\n",
    "\n",
    "Desktop/laptops nowadays are able to deliver **a peak performance** on the order of several GigaFLOPS. 1 GigaFLOPS is $10^9$ FLOPS. At this point you might want to compare this figure with the one corresponding to the most powerful supercomputer in the world provided  in the **Rpeak** column of the [Top500 list](https://www.top500.org/lists/top500/2020/06/). The actual performance that one experiments when executing the implementation of an algorithm on a given computer actually depends on: (1) the ability of such program to efficiently exploit the underlying CPU (Central Processing Unit) and memory system; (2) the arithmetic intensity of the computation itself, i.e., how much memory accesses are required per floating-point operation. It turns out that the arithmetic intensity of matrix-vector product is relatively low. Indeed, for a Python reference implementation of matrix-vector implementation, like the ones we are going to develop in this assignment, one should not expect an effective performance higher than 10% of the peak performance of the computer. \n",
    "\n",
    "The number of floating-point operations of matrix-vector operations is of the order of $n^2$, i.e., it grows quadratically with $n$. Thus, we can compute the FLOPS dividing $n^2$ by the time consumed by the computer in order to perform matrix-vector multiplication. This is precisely what the function in the cell below does, which returns the number of MegaFLOPS. 1 MegaFLOPS is $10^6$ FLOPS. The parameter `f` is assumed to be a function object which conforms to the interface presented in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def compute_mflops(f,A,x):\n",
    "    ts = time.perf_counter() # Register time elapsed since a reference in the past\n",
    "    y=f(A,x)\n",
    "    te = time.perf_counter() # Register time elapsed since a reference in the past\n",
    "    tc = te-ts\n",
    "    time_accum=0.0\n",
    "    for i in range(0,10000):\n",
    "      ts  = time.perf_counter() # Register time elapsed since a reference in the past\n",
    "      y=f(A,x)\n",
    "      te  = time.perf_counter() # Register time elapsed since a reference in the past\n",
    "      tc = min(tc,te-ts)\n",
    "      time_accum += te-ts\n",
    "      if time_accum > 2:\n",
    "        break\n",
    "    n=A.shape[0]\n",
    "    return 1.0e-06*(float(n)*float(n))/tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><span style=\"color:red\">**Task 1 (1/14 points).**</span> Write a function `compute_euclidean_norm(x)` which computes the Euclidean norm of a 1D array `x`. You may or may not use vectorization for this function definition statement (as you prefer). **Hint**: use the Wikipedia article linked above to figure out how the Euclidean norm of a vector is defined.   \n",
    ">\n",
    "><span style=\"color:red\">**Task 2 (0.5/14 points).**</span> Write a function `compute_relative_error(y,ytilde)` which computes the relative error among two 1D arrays `y`, `ytilde` as defined above. This function must call to the function defined in Task 1.\n",
    ">\n",
    "><span style=\"color:red\">**Task 3 (2/14 points).**</span> Write a function `matvec_row_variant_scalar(A,x)` that implements the **scalar-wise**, **row-variant** of the matrix-vector multiplication, where`A`  a 2D array, and `x` is a 1D array. It MUST use two nested loops and scalar-wise access to the entries of $A$ and $x$. Check that your implementation is correct. For such purpose, use the code cells below.\n",
    ">\n",
    "><span style=\"color:red\">**Task 4 (2/14 points).**</span> Write a function `matvec_row_variant_vectorized(A,x)` that implements the **vectorized**, **row-variant** of the matrix-vector multiplication, where`A`  a 2D array, and `x` is a 1D array.. It MUST use a single `for` loop. The inner product must be vectorized using the `np.dot(x, y)` function, with `x` and `y` being 1D numpy arrays. Check that your implementation is correct. For such purpose, use the code cells below. Recall that you can call `help(np.dot)` in a jupyter notebook code cell in order to get the documentation a function.\n",
    ">\n",
    "><span style=\"color:red\">**Task 5 (2/14 points).**</span> Write a function `matvec_col_variant_scalar(A,x)` that implements the **scalar-wise**, **column-variant** of the matrix-vector multiplication, , where`A`  a 2D array, and `x` is a 1D array. It MUST use two nested loops and scalar-wise access to the entries of $A$ and $x$. Check that your implementation is correct. For such purpose, use the code cells below.\n",
    ">\n",
    "><span style=\"color:red\">**Task 6 (2/14 points).**</span> Write a function `matvec_col_variant_vectorized(A,x)` that implements the **vectorized**, **column-variant** of the matrix-vector multiplication, , where`A`  a 2D array, and `x` is a 1D array. It MUST use a single `for` loop. The AXPY product should be vectorized using vector notation. Check that your implementation is correct. For such purpose, use the code cells below.\n",
    ">\n",
    "><span style=\"color:red\">**Task 7 (0.5/14 points).**</span> Write a function `matvec_matmul(A,x)` that implements matrix-vector multiplication using a single call to `np.matmul(A,x)`, where`A`  a 2D array, and `x` is a 1D array. Check that your implementation is correct. For such purpose, use the code cells below.\n",
    ">\n",
    "><span style=\"color:red\">**Task 8 (2/14 points).**</span> Write code that generates a plot of MegaFLOPS versus $n$ for the 5 implementations of the matrix-vector product in Tasks 3-7. There will be 5 curves in the same plot, with a curve per each implementation. Restrict yourself to values of $n$ in the range $[1,1000]$. In order to reduce the computational demands of the experiment, consider values of $n$ scattered as $10,20,\\ldots,100,200,\\ldots,1000$. \n",
    ">Some considerations/hints:\n",
    "> * You should plan how to split the data generation into functions. For example, a function which generates a list with the different values of $n$ to be tested sounds reasonable. What else is needed? As usual, there is no single approach to organize a program, but we will pay special attention when evaluating this task to your ability to design concise functions (a function must do only one thing!), with high quality, documented interfaces. \n",
    "> * Recall that you can use the `compute_mflops` function defined above as a tool to solve this task. \n",
    "> * Try to minimize the number of applications that are running concurrently in your computer while performing the experiment in order to obtain meaningful results. \n",
    "> * In the computer in which  this code was run (`Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz`), with Python version `v3.7.6`, it took around 2.5 minutes to obtain the data required to generate the 5 curves in the plot. Thus, please be patient while waiting for the results.\n",
    "> * If you fail to obtain the data required to generate the plot of Task 8, or you cannot make any sense out of the data that you generated, then you can use the data provided in the last cell of the notebook as a fallback, last-chance solution to generate the plot and answer to the questions in Task 9. These data was generated in a computer equipped with an `Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz` CPU,  with Python version `v3.7.6`, and thus might look to some extent different to the ones that you obtain in your computer. Note that Task 8 will be marked accordingly to the code that you wrote to generate the data required in order to generate the plot.\n",
    ">\n",
    "><span style=\"color:red\">**Task 9 (2/14 points).**</span> Discuss with your own words in a text cell the results obtained in Task 8. For example, how the different implementations rank compared to each other? Which is the fastest? Which is the slowest? How do the MegaFLOPS curves evolve with $n$? Include any observation that you consider relevant to your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 1 goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 2 goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 3 goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 4 goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 5 goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 6 goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 7 goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper code to test matrix-vector implementations\n",
    "import numpy as np\n",
    "def compute_relative_error_against_matmul(f,A,x):\n",
    "    y_f=f(A,x)\n",
    "    y_matmul=np.matmul(A,x)\n",
    "    return compute_relative_error(y_matmul,y_f)\n",
    "\n",
    "def generate_random_square_matrix(n):\n",
    "    return np.random.rand(n,n)\n",
    "\n",
    "def generate_random_vector(n):\n",
    "    return np.random.rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to test tasks 3-7\n",
    "l=[matvec_row_variant_scalar,\n",
    "   matvec_row_variant_vectorized,\n",
    "   matvec_col_variant_scalar,\n",
    "   matvec_col_variant_vectorized,\n",
    "   matvec_matmul]\n",
    "\n",
    "A=generate_random_square_matrix(10)\n",
    "x=generate_random_vector(10)\n",
    "\n",
    "for f in l:\n",
    "  print(f\"--- Testing {f.__name__}:\",end=\" \")\n",
    "  e=compute_relative_error_against_matmul(f,A,x)\n",
    "  if e > 1e-12:\n",
    "    print(f\"... {e} < {1e-12}? --> {e<1e-12}. Incorrect!!! Review implementation.\")  \n",
    "  else:\n",
    "    print(f\"... {e} < {1e-12}? --> {e<1e-12}. Correct!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Task 8 goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to help you out generating the plot required in Task 8\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(values_of_n, mflops_matvec_row_variant_scalar,label=\"rvs\")\n",
    "plt.plot(values_of_n, mflops_matvec_row_variant_vectorized,label=\"rvv\")\n",
    "plt.plot(values_of_n, mflops_matvec_col_variant_scalar,label=\"cvs\")\n",
    "plt.plot(values_of_n, mflops_matvec_col_variant_vectorized,label=\"cvv\")\n",
    "plt.plot(values_of_n, mflops_matvec_matmul,label=\"cvs\")\n",
    "\n",
    "plt.rcParams['legend.loc']='lower right'\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('MFLOPS')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answers to questions in Task 9 in this cell \n",
    "# Use Python code comments (i.e, lines starting with #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you fail to obtain the data required to generate the plot of Task 8, or \n",
    "# you cannot make any sense out of the data that you generated, then you can use the \n",
    "# data provided below as a fallback, last-chance solution to answer to the questions \n",
    "# in Task 9. These data was generated in a Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz`), \n",
    "# with Python version `v3.7.6`, and thus might look to some extent different to the\n",
    "# ones that you obtain in your computers. Note that Task 8 will be marked accordingly \n",
    "# to the code that you wrote to generate the data required in order to generate the plot.\n",
    "\n",
    "values_of_n=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "mflops_matvec_row_variant_scalar=[1.969124151393475, 2.111653689722419, 2.1308634311551846, \n",
    "                                  2.152073591185771, 2.0753794436718516, 2.091018550848754, \n",
    "                                  1.9748827164187008, 1.8979231682280697, 1.8871331304652257, \n",
    "                                  1.8811514834080865, 1.8185234527243108, 1.8622404329078828, \n",
    "                                  1.8386648581228635, 1.839629313806703, 1.8231414719766617, \n",
    "                                  1.8340406691757491, 1.8671332733816963, 1.809483527291526, \n",
    "                                  1.8040121685228072]\n",
    "\n",
    "mflops_matvec_row_variant_vectorized=[9.418857319021503, 20.113641840030276, 30.76502469502982, \n",
    "                                      41.443261012127394, 51.33891922459563, 61.29746287051146, \n",
    "                                      70.96409832050709, 83.5705513090586, 93.00082738565675, \n",
    "                                      105.43407192109875, 206.98898450461456, 297.95799475893347, \n",
    "                                      390.77096622364047, 486.5962201113236, 564.744860979354, \n",
    "                                      652.0171276460759, 714.806661111574, 787.7561298807864, \n",
    "                                      781.8950630238446]\n",
    "\n",
    "mflops_matvec_col_variant_scalar=[1.8778285020439505, 1.9118722590990571, 1.9317450073238627, \n",
    "                                  1.9212295861212434, 1.9334835253126357, 1.8388728521916735, \n",
    "                                  1.8503818952357949, 1.8762072594715478, 1.8520885495275032, \n",
    "                                  1.849587134809119, 1.8215095505183878, 1.8486435803897734, \n",
    "                                  1.8138802629820499, 1.789176546815382, 1.796023397660986, \n",
    "                                  1.782361594696548, 1.7636950403137426, 1.770207212002994, \n",
    "                                  1.8471039805274063]\n",
    "\n",
    "mflops_matvec_col_variant_vectorized=[6.334325735733227, 12.881618333295549, 19.771094978780386, \n",
    "                                      26.38522392154612, 32.60855463663772, 39.819044866818864, \n",
    "                                      45.855246963433494, 53.13760959226407, 57.82905396335357, \n",
    "                                      63.910014847194425, 105.4312931906004, 142.38253439215148, \n",
    "                                      181.2025051638151, 203.48778057307294, 217.82168627326715, \n",
    "                                      249.08777942411166, 251.71609419715583, 295.7881951080462, \n",
    "                                      268.38468660713255]\n",
    "\n",
    "mflops_matvec_matmul=[95.87732957001717, 384.9857589254826, 812.274957355831, \n",
    "                      1386.480074242417, 1876.8762209825545, 2321.0838998826043,\n",
    "                      2870.533632183864, 3418.8030321181795, 3911.1515947923003,\n",
    "                      2481.38949972828, 6955.313628038569, 11871.784226720787, \n",
    "                      13818.118072980446, 13541.327914659032, 13100.913433320491, \n",
    "                      13784.954819770315, 15403.499692420091, 15410.958679015028, \n",
    "                      15456.734412311678]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
